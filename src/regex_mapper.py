# -*- coding: utf-8 -*-
"""regex_mapper.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16p1-RLac6aOYI1wLGkeN3IvcTi_QoMnW
"""

import re
import json
import csv
from pathlib import Path

# 1. Build improved regex patterns
# =============================

def build_statute_patterns():
    """
    Build regex patterns to extract statute references like:
      302
      376(2)(g)
      120-B
      120B
      234(b), 234-b, 234b
    without truncation.
    """

    flags = re.IGNORECASE | re.UNICODE

    # Full statute-id pattern
    STATUTE_ID = r'[0-9]{1,4}(?:\([0-9A-Za-z]+\)|-[A-Za-z]|[A-Za-z]){0,3}'

    patterns = []

    # Section ... pattern
    patterns.append((
        "section_keyword",
        re.compile(
            rf'\b(?:section|sections|sec|secs|s|§)\.?\s*[:\s]*({STATUTE_ID})',
            flags
        )
    ))

    # IPC prefix
    patterns.append((
        "ipc_prefix",
        re.compile(
            rf'\b(?:ipc|indian\s+penal\s+code)[\s_:,\-]*({STATUTE_ID})',
            flags
        )
    ))

    # Section X of/under IPC
    patterns.append((
        "section_of_ipc",
        re.compile(
            rf'\bsections?\s*({STATUTE_ID})\s*(?:of|under)\s*(?:the\s*)?(?:ipc|indian\s+penal\s+code)\b',
            flags
        )
    ))

    # X IPC
    patterns.append((
        "num_then_ipc",
        re.compile(
            rf'({STATUTE_ID})\s*(?:,?\s*ipc|,?\s*indian\s+penal\s+code)\b',
            flags
        )
    ))

    # Articles
    patterns.append((
        "article",
        re.compile(
            r'\b(?:article|art)\.?\s*[:\s]*([0-9]{1,3}(?:[A-Za-z]|\([0-9A-Za-z]+\))?)',
            flags
        )
    ))

    # Bare fallback
    patterns.append((
        "bare_number_with_letter",
        re.compile(r'\b([0-9]{1,4}[A-Za-z])\b', flags)
    ))

    return patterns

# 2. Text normalization
# =============================

ZERO_WIDTH = ['\u200b', '\u200c', '\u200d', '\ufeff']

def normalize_text_for_matching(s: str):
    if s is None:
        return ""
    s2 = s.replace('\u00A0', ' ')  # NBSP to space
    for z in ZERO_WIDTH:
        s2 = s2.replace(z, '')
    s2 = re.sub(r'\s+', ' ', s2)
    return s2

# 3. Find statutes in a given sentence
# =============================

def find_statutes_in_text(text, patterns=None):
    """
    Return list of matches:
        {
            pattern_name,
            match_text,
            statute_raw,
            span_start,
            span_end
        }
    """

    if text is None:
        return []

    patterns = patterns or build_statute_patterns()

    s = text
    norm = normalize_text_for_matching(s)

    results = []

    # We search on normalized, but span mapping happens on raw
    for pname, pat in patterns:
        for m in pat.finditer(norm):
            raw_group = m.group(1)
            matched_norm = m.group(0)

            # Find same substring in original text
            idx = s.find(raw_group)
            if idx == -1:
                # fallback: try case-insensitive search
                lower_raw = raw_group.lower()
                idx = s.lower().find(lower_raw)

            if idx != -1:
                results.append({
                    "pattern_name": pname,
                    "match_text": matched_norm,
                    "statute_raw": raw_group,
                    "span_start": idx,
                    "span_end": idx + len(raw_group)
                })

    return results

# 4. Apply to JSONL file
# =============================

def map_jsonl_file_to_hits(jsonl_path, out_csv, include_legal_terms=True):
    """
    Reads JSONL lines of:
        { "page":..., "line_id":..., "start_char":..., "end_char":..., "text":... }
    Extracts statute references into CSV.
    """

    jsonl_path = str(jsonl_path)
    out_csv = str(out_csv)

    patterns = build_statute_patterns()
    rows = []

    with open(jsonl_path, "r", encoding="utf-8") as fin:
        for line_no, line in enumerate(fin):
            rec = json.loads(line)
            txt = rec.get("text", "") or ""

            page = rec.get("page")
            line_id = rec.get("line_id")
            start_char = rec.get("start_char")

            hits = find_statutes_in_text(txt, patterns=patterns)

            for h in hits:
                rows.append({
                    "line_no": line_no,
                    "page": page,
                    "line_id": line_id,
                    "sentence_text": txt,
                    "statute_raw": h["statute_raw"],
                    "pattern_name": h["pattern_name"],
                    "match_text": h["match_text"],
                    "local_start": h["span_start"],
                    "local_end": h["span_end"],
                    "global_start": (start_char + h["span_start"])
                                    if isinstance(start_char, int) else None,
                    "global_end": (start_char + h["span_end"])
                                  if isinstance(start_char, int) else None
                })

    # Write CSV
    if rows:
        with open(out_csv, "w", encoding="utf-8", newline="") as fout:
            writer = csv.DictWriter(fout, fieldnames=list(rows[0].keys()))
            writer.writeheader()
            for r in rows:
                writer.writerow(r)
        print(f"Wrote {len(rows)} hits → {out_csv}")
    else:
        print(f"Wrote 0 hits → {out_csv}")
        with open(out_csv, "w", encoding="utf-8", newline="") as fout:
            writer = csv.writer(fout)
            writer.writerow([
                "line_no","page","line_id","sentence_text",
                "statute_raw","pattern_name","match_text",
                "local_start","local_end","global_start","global_end"
            ])

    return rows

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/Hitika-Jain/LegalTalk.git

# %cd LegalTalk

